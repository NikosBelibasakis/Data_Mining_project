import pandas as pd
import numpy as np
from glob import glob
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam


# The path to the new_data folder
csv_folder_path = "new_data/"

# Fetch all the csv files from the folder
csv_files = glob(csv_folder_path + "*.csv")

# Initialize lists to hold training and test data
train_data = []
test_data = []

# Process each CSV file
for file in csv_files:
    df = pd.read_csv(file)
    
    # Drop unnecessary columns
    df = df.drop(columns=['index', 'Unnamed: 0'], errors='ignore')
    
    # Drop the 'timestamp' attribute
    df = df.drop(columns=['timestamp'])
    
    # Get 2200 rows from the start
    start_df = df.head(2200)
    
    # Get 2200 rows from the end
    end_df = df.tail(2200)
    
    # Get 2200 rows from the middle
    middle_index = len(df) // 2
    middle_df = df.iloc[middle_index - 1100: middle_index + 1100]
    
    # Combine the start, middle, and end data for training
    train_df = pd.concat([start_df, middle_df, end_df])
    
    # Get the rows from position 4000 to 5400 for testing
    test_df = df.iloc[4000:5400]
    
    # Append to the lists
    train_data.append(train_df)
    test_data.append(test_df)

# Concatenate all training and test data
train_data = pd.concat(train_data, ignore_index=True)
test_data = pd.concat(test_data, ignore_index=True)

# Separate the input data from the output data (label)
x_train = train_data.drop(columns=['label'])
y_train = train_data['label']
x_test = test_data.drop(columns=['label'])
y_test = test_data['label']


# Creation of the Neural Network
model = Sequential()

# Input layer with 6 neurons
model.add(Dense(6, input_dim=6))

# Hidden layer with 9 neurons and ReLU as the activation function
model.add(Dense(9, activation='relu'))

# Output layer with 12 neurons and softmax as the activation function
model.add(Dense(12, activation='softmax'))

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0055), metrics=['accuracy'])

# Train the model with validation split
history = model.fit(x_train, y_train, epochs=4, validation_split=0.1)

# Use the test set to evaluate the Neural Network
loss, accuracy = model.evaluate(x_test, y_test)
print(f'Test Loss: {loss:.3f}')
print(f'Test Accuracy: {accuracy:.3f}')


# Predict the label for 10 random records
num_samples = 10

#Get 10 random indices from the x_test data set
random_indices = np.random.randint(0, len(x_test), size=num_samples)

for i, random_index in enumerate(random_indices):
    random_sample = x_test.iloc[random_index].values.reshape(1, -1)  # Reshape to match model's expected input shape
    actual_label = y_test.iloc[random_index]
    
    # Make the prediction
    prediction = model.predict(random_sample)
    predicted_label = np.argmax(prediction)
    
    # Display the random sample and the label prediction
    print(f'\nSample {i+1}:')
    print(f'Random Sample Index: {random_index}')
    print(f'Input Features: {random_sample}')
    print(f'Actual Label: {actual_label}')
    print(f'Predicted Label: {predicted_label}')
    